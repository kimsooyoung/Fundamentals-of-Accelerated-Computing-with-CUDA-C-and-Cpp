{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-hello\t   07-vector-add       hello-gpu\r\n",
      "02-first-parallel  08-matrix-multiply  images\r\n",
      "03-indices\t   09-heat\t       mismatched-config-loop\r\n",
      "04-loops\t   AC_CUDA_C.ipynb     multi-block-loop\r\n",
      "05-allocate\t   double-elements     single-block-loop\r\n",
      "06-errors\t   first-parallel      thread-and-block-idx\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git config --global user.name \"kimsooyoung\"\n",
    "! git config --global user.email \"tge1375@naver.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: remote origin already exists.\n",
      "error: src refspec main does not match any.\n",
      "error: failed to push some refs to 'https://github.com/kimsooyoung/Fundamentals-of-Accelerated-Computing-with-CUDA-C-and-Cpp.git'\n"
     ]
    }
   ],
   "source": [
    "!git remote add origin https://github.com/kimsooyoung/Fundamentals-of-Accelerated-Computing-with-CUDA-C-and-Cpp.git\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master c50feb2] Update : Grid Stride\r\n",
      " 4 files changed, 4305 insertions(+), 49 deletions(-)\r\n",
      " create mode 100755 grid-stride-double\r\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Update : Grid Stride\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: remote origin already exists.\r\n"
     ]
    }
   ],
   "source": [
    "!git remote add origin git@github.com:kimsooyoung/Fundamentals-of-Accelerated-Computing-with-CUDA-C-and-Cpp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! git remote set-url origin git@github.com:kimsooyoung/Fundamentals-of-Accelerated-Computing-with-CUDA-C-and-Cpp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git config --global push.default matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# github.com:22 SSH-2.0-babeld-517b8896\n",
      "# github.com:22 SSH-2.0-babeld-517b8896\n",
      "# github.com:22 SSH-2.0-babeld-517b8896\n"
     ]
    }
   ],
   "source": [
    "! ssh-keyscan github.com >> ~/.ssh/known_hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission denied (publickey).\r",
      "\r\n",
      "fatal: Could not read from remote repository.\r\n",
      "\r\n",
      "Please make sure you have the correct access rights\r\n",
      "and the repository exists.\r\n"
     ]
    }
   ],
   "source": [
    "!git push origin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:kimsooyoung/Fundamentals-of-Accelerated-Computing-with-CUDA-C-and-Cpp.git (fetch)\r\n",
      "origin\tgit@github.com:kimsooyoung/Fundamentals-of-Accelerated-Computing-with-CUDA-C-and-Cpp.git (push)\r\n"
     ]
    }
   ],
   "source": [
    "!git remote -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task\n",
      "/dli/task\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!cd ../\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 41%\r",
      "\r",
      "Reading package lists... Done\r",
      "\r\n",
      "\r",
      "Building dependency tree... 0%\r",
      "\r",
      "Building dependency tree... 0%\r",
      "\r",
      "Building dependency tree... 50%\r",
      "\r",
      "Building dependency tree... 50%\r",
      "\r",
      "Building dependency tree       \r",
      "\r\n",
      "\r",
      "Reading state information... 0%\r",
      "\r",
      "Reading state information... 1%\r",
      "\r",
      "Reading state information... Done\r",
      "\r\n",
      "E: Unable to locate package git-all\r\n"
     ]
    }
   ],
   "source": [
    "!apt install git-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add README.md\n",
    "!git commit -m \"first commit\"\n",
    "!git branch -M main\n",
    "!git remote add origin https://github.com/kimsooyoung/Fundamentals-of-Accelerated-Computing-with-CUDA-C-and-Cpp.git\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1>CUDA C/C++를 통한 애플리케이션 가속화</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CUDA](./images/CUDA_Logo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가속 컴퓨팅은 모범 사례로서 CPU 전용 컴퓨팅을 대체하고 있습니다. 가속 컴퓨팅에 기반한 일련의 혁신, 계속 증가하는 가속 애플리케이션에 대한 수요, 작성을 용이하게 하는 프로그래밍 규칙, 이를 지원하는 하드웨어의 지속적인 개선이 이 필연적인 전환을 이끌고 있습니다.\n",
    "\n",
    "놀라운 성능과 사용 편의성이라는 두 측면 모두에 있어서, 가속 컴퓨팅이 거둔 성공의 중심에는 [CUDA](https://developer.nvidia.com/about-cuda) 컴퓨팅 플랫폼이 자리하고 있습니다. CUDA는 C, C++, Python, Fortran 등 다양한 언어를 확장하는 코딩 패러다임을 제공함으로써 세계에서 가장 성능이 뛰어난 병렬 프로세서인 NVIDIA GPU에서 가속화된 대규모 병렬 코드를 실행할 수 있습니다. CUDA는 최소한의 노력으로 애플리케이션을 대폭 가속화하고, [DNN](https://developer.nvidia.com/cudnn), [BLAS](https://developer.nvidia.com/cublas), [그래프 분석](https://developer.nvidia.com/nvgraph), [FFT](https://developer.nvidia.com/cufft) 등을 위해 고도로 최적화된 라이브러리의 에코시스템을 갖추고 있으며, 강력한 [명령줄 및 비주얼 프로파일러](https://developer.nvidia.com/nsight-systems)를 제공합니다.\n",
    "\n",
    "CUDA는 [전산 유체 역학](https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/catalog/?product_category_id=10,12,16,17,19,51,53,71,87,121,124,156,157,195,202,203,204,312,339,340,395,407,448,485,517,528,529,541,245,216,104,462,513,250,492,420,429,490,10,12,16,17,19,51,53,71,87,121,124,156,157,195,202,203,204,312,339,340,395,407,448,485,517,528,529,541,245,216,104,462,513,250,492,420,429,490,10,12,16,17,19,51,53,71,87,121,124,156,157,195,202,203,204,312,339,340,395,407,448,485,517,528,529,541,245,216,104,462,513,250,492,420,429,490&search=), [분자 동역학](https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/catalog/?product_category_id=8,57,92,123,211,213,237,272,274,282,283,307,325,337,344,345,351,362,365,380,396,398,400,435,507,508,519,8,57,92,123,211,213,237,272,274,282,283,307,325,337,344,345,351,362,365,380,396,398,400,435,507,508,519,8,57,92,123,211,213,237,272,274,282,283,307,325,337,344,345,351,362,365,380,396,398,400,435,507,508,519,8,57,92,123,211,213,237,272,274,282,283,307,325,337,344,345,351,362,365,380,396,398,400,435,507,508,519&search=), [양자 화학](https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/catalog/?product_category_id=8,57,92,123,211,213,237,272,274,282,283,307,325,337,344,345,351,362,365,380,396,398,400,435,507,508,519,8,57,92,123,211,213,237,272,274,282,283,307,325,337,344,345,351,362,365,380,396,398,400,435,507,508,519&search=), [물리학](https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/catalog/?product_category_id=6,24,116,118,119,135,229,231,372,373,392,393,489,493,494,495,496,497,498,67,170,216,281,6,24,116,118,119,135,229,231,372,373,392,393,489,493,494,495,496,497,498,67,170,216,281,6,24,116,118,119,135,229,231,372,373,392,393,489,493,494,495,496,497,498,67,170,216,281,6,24,116,118,119,135,229,231,372,373,392,393,489,493,494,495,496,497,498,67,170,216,281,6,24,116,118,119,135,229,231,372,373,392,393,489,493,494,495,496,497,498,67,170,216,281&search=), HPC 등 각 분야별로 [세계에서 가장 성능이 뛰어난 애플리케이션](https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/catalog/?product_category_id=58,59,60,293,98,172,223,227,228,265,487,488,114,389,220,258,461&search=)의 대부분을 지원합니다.\n",
    "\n",
    "CUDA를 학습하면 애플리케이션을 직접 가속화하실 수 있습니다. 가속 애플리케이션은 CPU 전용 애플리케이션보다 훨씬 빠르게 수행되며, CPU 전용 애플리케이션의 제한된 성능으로 인해 할 수 없었던 연산을 가능하게 합니다. 이 실습에서는 CUDA C/C++을 통한 가속 애플리케이션 프로그래밍 기초를 배우게 되며, 여러분이 성능 증가와 새로운 컴퓨팅 영역으로의 진출을 위해 직접 CPU 전용 애플리케이션 가속화 작업을 시작하기에 충분한 콘텐츠입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 전제 조건\n",
    "\n",
    "이 실습을 최대한 잘 활용하려면 여러분은 이미 다음을 하실 수 있어야 합니다.\n",
    "\n",
    "- C 언어로 변수 선언, 루프 작성, if/else 문 사용\n",
    "- C 언어로 함수 정의 및 호출\n",
    "- C 언어로 어레이 할당\n",
    "\n",
    "CUDA 사전 지식은 필요하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 목표\n",
    "\n",
    "이 실습을 완료할 때는 다음을 하실 수 있게 됩니다.\n",
    "\n",
    "- CPU 함수를 호출하고 **GPU** 커널을 **실행하는** C/C++ 프로그램 작성, 컴파일, 실행\n",
    "- **실행 구성**을 이용한 병렬 **스레드 계층 구조** 제어\n",
    "- 직렬 루프를 GPU에서 병렬로 반복 실행하도록 리팩터링\n",
    "- CPU와 GPU 둘 다에서 사용할 수 있는 메모리 할당 및 해제\n",
    "- CUDA 코드로 생성된 오류 처리\n",
    "- CPU 전용 애플리케이션 가속화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 가속 시스템\n",
    "\n",
    "*가속 시스템*은 *이종 시스템*이라고도 하며, CPU와 GPU 둘 다로 구성됩니다. 가속 시스템은 CPU 프로그램을 실행하며, 결과적으로 GPU가 제공하는 대규모 병렬 처리의 이점을 활용할 수 있는 함수를 실행합니다. 이 실습 환경은 NVIDIA GPU가 포함된 가속 시스템입니다. 이 GPU에 대한 정보는 `nvidia-smi` (*시스템 관리 인터페이스*) 명령줄 명령으로 쿼리할 수 있습니다. `nvidia-smi` 명령을 지시하려면 아래의 코드 실행 셀에서 `CTRL` + `ENTER`를 누르세요. 코드 실행이 필요하면 언제든지 이 실습 전반에 걸쳐 이러한 셀을 찾을 수 있습니다. 명령 실행의 출력값은 코드 실행 후 코드 실행 셀 바로 아래에 출력됩니다. 아래에서 코드 실행 블록을 실행한 후에는 바로 출력값에 있는 GPU의 이름을 찾아 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi | grep MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -l 1 | grep MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 15 00:30:55 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.118.02   Driver Version: 440.118.02   CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  On   | 00000001:00:00.0 Off |                  Off |\r\n",
      "| N/A   29C    P0    23W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## GPU 가속 애플리케이션과 CPU 전용 애플리케이션 비교\n",
    "\n",
    "다음 슬라이드에서는 앞으로 다룰 콘텐츠를 고수준에서 시각적으로 보여드립니다. 다음 섹션으로 넘어가 각 주제를 더 자세히 다루기 전에 슬라이드를 클릭해 보세요.\n",
    "\n",
    "<script>console.log('hi');</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vQsmItghQMFR_wq8ybFjdt-jeh29ueiOY-79IWUvZqRdxoQysMsBxJwQbrmOhqS5SMQJA3LCbj_9GDV/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vQsmItghQMFR_wq8ybFjdt-jeh29ueiOY-79IWUvZqRdxoQysMsBxJwQbrmOhqS5SMQJA3LCbj_9GDV/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## GPU용 애플리케이션 코드 작성\n",
    "\n",
    "CUDA는 다수의 일반적인 프로그래밍 언어, 이 실습의 경우에는 C/C++에 대한 확장을 제공합니다. 이러한 언어 확장을 통해 개발자는 GPU의 소스 코드에서 함수를 쉽게 실행할 수 있습니다.\n",
    "\n",
    "아래에 `.cu` 파일이 하나 있습니다(`.cu` 는 CUDA 가속 프로그램의 파일 확장자입니다). 두 개의 함수가 포함되어 있는데, 첫 번째 함수는 CPU에서, 두 번째 함수는 GPU에서 실행됩니다. 시간을 들여 함수가 정의되는 방식과 호출되는 방식 모두에서 함수 간의 차이를 파악해 보세요.\n",
    "\n",
    "```cpp\n",
    "void CPUFunction()\n",
    "{\n",
    "  printf(\"This function is defined to run on the CPU.\\n\");\n",
    "}\n",
    "\n",
    "__global__ void GPUFunction()\n",
    "{\n",
    "  printf(\"This function is defined to run on the GPU.\\n\");\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  CPUFunction();\n",
    "\n",
    "  GPUFunction<<<1, 1>>>();\n",
    "  cudaDeviceSynchronize();\n",
    "}\n",
    "```\n",
    "\n",
    "다음은 강조할 만한 몇 가지 중요한 코드 줄과 가속 컴퓨팅에 사용되는 기타 일반적인 용어입니다.\n",
    "\n",
    "`__global__ void GPUFunction()`\n",
    "  - `__global__` 키워드는 다음 기능이 GPU에서 실행되며, **전역**에서, 즉 이 맥락에서는 CPU나 GPU 중 어느 쪽에서든 호출할 수 있음을 나타냅니다.\n",
    "  - CPU에서 실행되는 코드는 보통 **호스트** 코드, GPU에서 실행되는 코드는 **디바이스** 코드라고 부릅니다.\n",
    "  - 반환 형식이 `void`인 것을 볼 수 있습니다. `__global__` 키워드로 정의된 함수는 `void` 형식을 반환해야 합니다.\n",
    "\n",
    "`GPUFunction<<<1, 1>>>();`\n",
    "  - 일반적으로 함수를 GPU에서 실행되도록 호출할 때, **커널**이라고 부르는 이 함수가 **실행**됩니다.\n",
    "  - 커널을 실행할 때는 **실행 구성**을 제공해야 하며, 이는 커널에 예상되는 모든 인수를 전달하기 바로 전에 `<<< ... >>>` 구문을 사용하여 처리됩니다.\n",
    "  - 고수준에서 프로그래머는 실행 구성을 통해 커널 실행을 위한 **스레드 계층 구조**를 지정할 수 있고, 이는 스레드 그룹(**블록**이라고 부름) 수와 각 블록에서 실행될 **스레드**의 수를 정의합니다. 실행 구성에 대해서는 실습 후반에 매우 상세하게 알아보겠지만, 지금은 커널이 `1` 스레드(두 번째 구성 인수)를 포함하는 `1` 스레드 블록으로 실행되고 있음을 알 수 있습니다.\n",
    "\n",
    "`cudaDeviceSynchronize();`\n",
    "  - 많은 C/C++ 코드와는 달리 커널 실행은 **비동기** 연산입니다. CPU 코드는 *커널 실행이 완료될 때까지 기다리지 않고 계속 실행됩니다*.\n",
    "  - `cudaDeviceSynchronize` 호출은 CUDA 런타임에서 제공하는 함수로, 이 함수를 사용하면 호스트(CPU) 코드가 디바이스(GPU) 코드가 완료될 때까지 기다렸다가 CPU에서만 다시 실행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: Hello GPU 커널 작성\n",
    "\n",
    "[`01-hello-gpu.cu`](../edit/01-hello/01-hello-gpu.cu) (*<---- 소스 파일 링크를 클릭하면 다른 탭에서 열어 편집할 수 있습니다*)에는 이미 작동하고 있는 프로그램이 포함되어 있습니다. 여기에는 \"Hello from the CPU\"라는 메시지를 출력하는 두 개의 함수가 포함되어 있습니다. 여러분의 목표는 `helloGPU` 함수를 소스 파일에서 리팩터링하여 GPU에서 실제로 실행되도록 하고, 이것을 나타내는 메시지를 출력하는 것입니다.\n",
    "\n",
    "- 바로 아래에서 `nvcc` 명령으로 애플리케이션을 컴파일링하고 실행하기 전 애플리케이션을 리팩터링하세요(`CTRL + ENTER`를 눌러 코드 실행 셀의 콘텐츠를 실행할 수 있다는 것을 기억하세요). [`01-hello-gpu.cu`](../edit/01-hello/01-hello-gpu.cu) 안의 메모가 작업에 도움을 드릴 것입니다. 작업 중 막혔거나 여러분의 작업을 확인하고자 하는 경우 [해답](../edit/01-hello/solutions/01-hello-gpu-solution.cu)을 참고하세요. 아래의 명령으로 컴파일링하고 실행하기 전에 변경 사항을 파일에 저장하는 것을 잊지 마세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from the CPU.\n",
      "Hello also from the CPU.\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 -o hello-gpu 01-hello/01-hello-gpu.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`01-hello-gpu.cu`](../edit/01-hello/01-hello-gpu.cu) 리팩터링에 성공하고 나면, 다음 콘텐츠대로 수정하면서 수정할 때마다 컴파일 및 실행을 시도해 보세요(위의 코드 실행 셀에서 `CTRL + ENTER`를 누르면 됩니다). 오류가 발생하면 시간을 들여 신중하게 읽어보십시오. 이러한 오류에 익숙해지면 가속 코드를 작성하기 시작할 때 큰 도움이 될 것입니다.\n",
    "\n",
    "- 커널 정의에서 `__global__` 키워드를 제거하세요. 오류의 줄 번호를 주의깊게 살펴보세요. 오류에 있는 \"configured\"는 무슨 뜻일까요? 완료되면 `__global__`을 교체하세요.\n",
    "- 실행 구성을 제거하세요. 여러분이 이해한 ”configured”의 뜻이 여전히 말이 되나요? 완료되면 실행 구성을 교체하세요.\n",
    "- `cudaDeviceSynchronize`로의 호출을 제거하세요. 코드를 컴파일 및 실행하기 전에 커널이 비동기적으로 실행된다는 것과 `cudaDeviceSynchronize`가 커널 실행이 완료될 때까지 호스트 실행을 대기하게 만든다는 것을 기억하면서 무슨 일이 일어날지 추측해 보세요. 완료되면 `cudaDeviceSynchronize`로의 호출을 교체하세요.\n",
    "- `01-hello-gpu.cu`를 리팩터링하여 `Hello from the GPU`가 `Hello from the CPU` **전에** 출력되게 하세요.\n",
    "- `01-hello-gpu.cu`를 리팩터링하여 `Hello from the GPU`가 `Hello from the CPU` **앞에** 한 번, **뒤에** 한 번으로 **두 번** 출력되게 하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 가속 CUDA 코드 컴파일 및 실행\n",
    "\n",
    "이 섹션에서는 여러분이 위에서 지시한 `nvcc` 명령으로 `.cu` 프로그램을 컴파일 및 실행하는 방법을 자세히 다룹니다.\n",
    "\n",
    "CUDA 플랫폼에는 [**NVIDIA CUDA 컴파일러**](http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html) `nvcc`가 탑재되어 있어 CUDA 가속 애플리케이션에 포함된 호스트 코드와 디바이스 코드를 모두 컴파일할 수 있습니다. 이 실습의 목적에 맞게, `nvcc`에 대해서는 당장 필요한 만큼의 범위만 실용적으로 다룰 예정입니다. 실습을 완료한 후 `nvcc`에 대해 더 심도 있게 알고 싶으신 분은 이 [문서](http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html)로 시작하세요.\n",
    "\n",
    "`nvcc`는 숙련된 `gcc` 유저에게는 매우 익숙할 것입니다. 예를 들어, `some-CUDA.cu` 파일을 컴파일한다면 다음과 같이 쓰면 됩니다.\n",
    "\n",
    "`nvcc -arch=sm_70 -o out some-CUDA.cu -run`\n",
    "  - `nvcc`는 `nvcc` 컴파일러를 사용하는 명령줄 명령입니다.\n",
    "  - `some-CUDA.cu`가 컴파일할 파일로 전달됩니다.\n",
    "  - `o` 플래그는 컴파일된 프로그램의 출력 파일을 지정하는 데 사용됩니다.\n",
    "  - `arch` 플래그는 파일이 어떤 **아키텍처**로 컴파일되어야 하는지를 나타냅니다. 지금의 경우 `sm_70`이 이 실습이 실행 중인 GPU에 대해서만 컴파일하는 역할을 하지만, 더욱 심도 있게 알아보고 싶으신 분은 [`arch` 플래그](http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#options-for-steering-gpu-code-generation), [가상 아키텍처 기능](http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#gpu-feature-list), [GPU 기능](http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#gpu-feature-list)에 대한 문서를 참조하시기 바랍니다.\n",
    "  - 편의상 `run` 플래그가 성공적으로 컴파일된 바이너리를 실행한다고 가정하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## CUDA 스레드 계층 구조\n",
    "\n",
    "다음 슬라이드에서는 앞으로 다룰 콘텐츠를 고수준에서 시각적으로 보여드립니다. 다음 섹션으로 넘어가 각 주제를 더 자세히 다루기 전에 슬라이드를 클릭해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTrBXrw5-3ZwGG4utAcnrm12pzoX6Z0PCMh9iD0jQrbGZTxvv5Tj9UW1H-6J8S96KQjfJiFwQ5ALgAr/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTrBXrw5-3ZwGG4utAcnrm12pzoX6Z0PCMh9iD0jQrbGZTxvv5Tj9UW1H-6J8S96KQjfJiFwQ5ALgAr/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 병렬 커널 실행\n",
    "\n",
    "실행 구성을 통해 프로그래머는 여러 GPU **스레드**에서의 커널 병렬 실행에 대한 세부 정보를 지정할 수 있습니다. 더욱 정확하게 말하면, 프로그래머는 실행 구성을 통해 **스레드 블록** 또는 **블록**이라고 부르는 스레드 그룹의 수 및 각 스레드 블록에 포함될 스레드의 수를 지정할 수 있습니다. 이를 위한 구문은 다음과 같습니다.\n",
    "\n",
    "`<<< NUMBER_OF_BLOCKS, NUMBER_OF_THREADS_PER_BLOCK>>>`\n",
    "\n",
    "** 커널 코드는 커널이 실행될 때 구성된 모든 스레드 블록의 모든 스레드에 의해 실행됩니다**.\n",
    "\n",
    "따라서 `someKernel`이라는 커널이 정의되어 있다는 가정 하에, 다음 사항들은 참입니다.\n",
    "  - `someKernel<<<1, 1>>()`은 1개의 스레드를 가진 1개의 스레드 블록으로 실행하도록 구성되며, 따라서 한 번만 실행됩니다.\n",
    "  - `someKernel<<<1, 10>>()`은 10개의 스레드를 가진 1개의 스레드 블록으로 실행하도록 구성되며, 따라서 10번 실행됩니다.\n",
    "  - `someKernel<<<10, 1>>()`은 각각 1개의 스레드를 가진 10개의 스레드 블록으로 실행하도록 구성되며, 따라서 10번 실행됩니다.\n",
    "  - `someKernel<<<10, 10>>()`은 각각 10개의 스레드를 가진 10개의 스레드 블록으로 실행하도록 구성되며, 따라서 100번 실행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 병렬 커널 실행\n",
    "\n",
    "[`01-first-parallel.cu`](../edit/02-first-parallel/01-first-parallel.cu)는 현재 `This should be running in parallel.`이라는 메시지를 출력하는 매우 기본적인 함수를 호출합니다. 아래의 단계를 따라 처음에는 GPU에서 실행되도록 리팩터링하고, 다음에는 1개의 스레드 블록과 여러 개의 스레드 블록 모두에서 병렬로 실행되도록 해 보세요. 도중에 막히면 [해답](../edit/02-first-parallel/solutions/01-first-parallel-solution.cu)을 참고하세요.\n",
    "\n",
    "- `firstParallel` 함수가 GPU에서 CUDA 커널로 실행되도록 리팩터링하세요. 바로 아래의 `nvcc` 명령으로 `01-first-parallel.cu`를 컴파일 및 실행한 후에도 여전히 함수의 출력값을 볼 수 있습니다.\n",
    "- `firstParallel` 커널이 1개의 스레드 블록에서 실행되는 5개의 스레드에서 병렬로 실행되도록 리팩터링하세요. 코드 컴파일 및 실행 후 결과 메시지가 5번 출력되는 것을 볼 수 있습니다.\n",
    "- `firstParallel` 커널을, 이번에는 각각 5개 의 스레드가 포함된 5개의 스레드 블록 내에서 병렬로 실행하도록 리팩터링하세요. 컴파일 및 실행 후 결과 메시지가 25번 출력되는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be running in parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n",
      "This should be running in GPU parallel.\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 -o first-parallel 02-first-parallel/01-first-parallel.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CUDA에서 제공하는 스레드 계층 구조 변수\n",
    "\n",
    "다음 슬라이드에서는 앞으로 다룰 콘텐츠를 고수준에서 시각적으로 보여드립니다. 다음 섹션으로 넘어가 각 주제를 더 자세히 다루기 전에 슬라이드를 클릭해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vRggIc-Nxdya9NapAoVM6pZ2-73SwMdbe4h4i5EnugiMbnAxgXQePlB9WaWMvwbT39JlmAHiGhrG9EH/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vRggIc-Nxdya9NapAoVM6pZ2-73SwMdbe4h4i5EnugiMbnAxgXQePlB9WaWMvwbT39JlmAHiGhrG9EH/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 스레드 및 블록 색인\n",
    "\n",
    "각 스레드에는 스레드 블록 내에서 `0`부터 시작하는 색인이 주어집니다. 또한 각 블록에도 `0`부터 시작하는 색인이 주어집니다. 스레드가 모여 스레드 블록이 되듯이 블록이 모이면 **그리드**가 되며, 그리드는 CUDA 스레드 계층 구조의 최상위 엔터티입니다. 요약하면 CUDA 커널은 1개 이상의 블록으로 이루어진 그리드에서 실행되며, 각 블록에는 1개 이상의 스레드가 같은 개수로 들어 있습니다.\n",
    "\n",
    "CUDA 커널은 커널을 실행하는 스레드의 색인(블록 내)과 스레드가 들어 있는 블록의 색인(그리드 내)을 모두 식별하는 특수 변수에 액세스할 수 있습니다. 이 변수들은 각각 `threadIdx.x`와 `blockIdx.x`입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 특정 스레드 및 블록 색인 사용\n",
    "\n",
    "현재 [`01-thread-and-block-idx.cu`](../edit/03-indices/01-thread-and-block-idx.cu) 파일에는 실패 메시지를 출력하는 작동 중인 커널이 포함되어 있습니다. 파일을 열어 성공 메시지가 출력될 수 있도록 실행 구성을 업데이트하는 방법을 학습하세요. 리팩터링 후에는 아래의 코드 실행 셀로 코드를 컴파일 및 실행하여 작업을 확인하세요. 도중에 막히면 [해답](../edit/03-indices/solutions/01-thread-and-block-idx-solution.cu)을 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n",
      "Failure. Update the execution configuration as necessary.\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 -o thread-and-block-idx 03-indices/01-thread-and-block-idx.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## For 루프 가속\n",
    "\n",
    "CPU 전용 애플리케이션의 for 루프는 가속이 용이합니다. 루프의 각 반복을 직렬로 실행하기보다는 루프의 각 반복을 자체 스레드에서 병렬로 실행할 수 있습니다. For 루프에 대한 다음 사항을 고려하고, 당연한 사실이지만, 이것이 루프가 몇 번 실행될지를 제어하고 루프가 반복될 때마다 어떤 일이 일어날지 정의한다는 것도 알아두세요.\n",
    "\n",
    "```cpp\n",
    "int N = 2<<20;\n",
    "for (int i = 0; i < N; ++i)\n",
    "{\n",
    "  printf(\"%d\\n\", i);\n",
    "}\n",
    "```\n",
    "\n",
    "이 루프를 병렬화하려면 다음 2단계를 수행해야 합니다.\n",
    "\n",
    "- 하나의 커널은 **루프의 반복 한 번**에 해당하는 작업을 하도록 작성해야 합니다.\n",
    "- 해당 커널이 다른 실행 커널에 대해 모르는 상태이기 때문에, 커널을 올바른 횟수(예: 루프를 반복하는 횟수)만큼 실행하도록 실행 구성을 해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 1개의 스레드 블록으로 For 루프 가속\n",
    "\n",
    "현재 [`01-single-block-loop.cu`](../edit/04-loops/01-single-block-loop.cu) 안에 있는 `loop` 함수는 `0`부터 `9`까지의 숫자를 직렬로 출력하는 for 루프를 실행합니다. `loop` 함수가 `N`번의 반복을 병렬로 실행하는 CUDA 커널이 되도록 리팩터링하세요. 리팩터링에 성공한 뒤에도 여전히 `0`부터 `9`까지의 숫자가 출력되어야 합니다. 도중에 막히면 [해답](../edit/04-loops/solutions/01-single-block-loop-solution.cu)을 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is iteration number 0\n",
      "This is iteration number 1\n",
      "This is iteration number 2\n",
      "This is iteration number 3\n",
      "This is iteration number 4\n",
      "This is iteration number 5\n",
      "This is iteration number 6\n",
      "This is iteration number 7\n",
      "This is iteration number 8\n",
      "This is iteration number 9\n",
      "This is iteration GPU number 0\n",
      "This is iteration GPU number 0\n",
      "This is iteration GPU number 0\n",
      "This is iteration GPU number 0\n",
      "This is iteration GPU number 0\n",
      "This is iteration GPU number 0\n",
      "This is iteration GPU number 0\n",
      "This is iteration GPU number 0\n",
      "This is iteration GPU number 0\n",
      "This is iteration GPU number 0\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 -o single-block-loop 04-loops/01-single-block-loop.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 병렬 스레드 조정\n",
    "\n",
    "다음 슬라이드에서는 앞으로 다룰 콘텐츠를 고수준에서 시각적으로 보여드립니다. 다음 섹션으로 넘어가 각 주제를 더 자세히 다루기 전에 슬라이드를 클릭해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vRw3Cpp0Gh3GJx0TRhLMX3w9uO-QD7ZoFplWZAtUiblVKcCA1SSTKlmBD-ysiWJT3BHDop_O-OpRlYY/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vRw3Cpp0Gh3GJx0TRhLMX3w9uO-QD7ZoFplWZAtUiblVKcCA1SSTKlmBD-ysiWJT3BHDop_O-OpRlYY/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 더 많은 병렬화를 위한 블록 차원 사용\n",
    "\n",
    "하나의 스레드 블록에 존재할 수 있는 스레드의 수는 제한되어 있으며, 정확하게는 1024개입니다. 가속 애플리케이션에서 병렬 처리의 양을 늘리기 위해서는 여러 스레드 블록 사이를 조정할 수 있어야 합니다.\n",
    "\n",
    "CUDA 커널은 한 블록의 스레드 수를 알려주는 특수 변수인 `blockDim.x`에 액세스할 수 있습니다. 이 변수를 `blockIdx.x` 및 `threadIdx.x`와 함께 사용하면, 관용적인 `threadIdx.x + blockIdx.x * blockDim.x` 식으로 여러 개의 스레드가 있는 여러 개의 블록에 걸쳐 병렬 실행을 구성함으로써 더 많은 병렬 실행 달성이 가능합니다. 자세한 예시를 보여드리겠습니다.\n",
    "\n",
    "실행 구성 `<<<10, 10>>>`은 각각 10개의 스레드가 담긴 10개의 블록이 포함되어 총 100개의 스레드로 구성된 그리드를 실행합니다. 따라서 우리는 각 스레드가 자신이 가진 `0`부터 `99` 사이의 고유한 색인을 계산할 수 있기를 바랄 것입니다.\n",
    "\n",
    "- `blockIdx.x` 블록이 `0`과 같다면, `blockIdx.x * blockDim.x`는 `0`입니다. `0`에 `0`부터 `9`까지의 가능한 `threadIdx.x` 값을 더하면, 스레드 100개짜리 그리드 내에서 `0`부터 `9`까지의 색인을 생성할 수 있습니다.\n",
    "- `blockIdx.x` 블록이 `1`과 같다면, `blockIdx.x * blockDim.x`는 `10`입니다. `10`에 `0`부터 `9`까지의 가능한 `threadIdx.x` 값을 더하면, 스레드 100개짜리 그리드 내에서 `10`부터 `19`까지의 색인을 생성할 수 있습니다.\n",
    "- `blockIdx.x` 블록이 `5`와 같다면, `blockIdx.x * blockDim.x`는 `50`입니다. `50`에 `0`부터 `9`까지의 가능한 `threadIdx.x` 값을 더하면, 스레드 100개짜리 그리드 내에서 `50`부터 `59`까지의 색인을 생성할 수 있습니다.\n",
    "- `blockIdx.x` 블록이 `9`와 같다면, `blockIdx.x * blockDim.x`는 `90`입니다. `90`에 `0`부터 `9`까지의 가능한 `threadIdx.x` 값을 더하면, 스레드 100개짜리 그리드 내에서 `90`부터 `99`까지의 색인을 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 여러 개의 스레드 블록으로 For 루프 가속\n",
    "\n",
    "현재 [`02-multi-block-loop.cu`](../edit/04-loops/02-multi-block-loop.cu) 안에 있는 `loop` 함수는 `0`부터 `9`까지의 숫자를 직렬로 출력하는 for 루프를 실행합니다. `loop` 함수가 `N`번의 반복을 병렬로 실행하는 CUDA 커널이 되도록 리팩터링하세요. 리팩터링에 성공한 뒤에도 여전히 `0`부터 `9`까지의 숫자가 출력되어야 합니다. 이 연습에서는 추가 제약 조건으로 *최소 2개의 스레드 블록*에서 실행되는 실행 구성을 사용하셔야 합니다. 도중에 막히면 [해답](../edit/04-loops/solutions/02-multi-block-loop-solution.cu)을 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is iteration number 0\n",
      "This is iteration number 1\n",
      "This is iteration number 2\n",
      "This is iteration number 3\n",
      "This is iteration number 4\n",
      "This is iteration number 5\n",
      "This is iteration number 6\n",
      "This is iteration number 7\n",
      "This is iteration number 8\n",
      "This is iteration number 9\n",
      "This is GPU iteration number 80\n",
      "This is GPU iteration number 81\n",
      "This is GPU iteration number 82\n",
      "This is GPU iteration number 83\n",
      "This is GPU iteration number 84\n",
      "This is GPU iteration number 85\n",
      "This is GPU iteration number 86\n",
      "This is GPU iteration number 87\n",
      "This is GPU iteration number 88\n",
      "This is GPU iteration number 89\n",
      "This is GPU iteration number 90\n",
      "This is GPU iteration number 91\n",
      "This is GPU iteration number 92\n",
      "This is GPU iteration number 93\n",
      "This is GPU iteration number 94\n",
      "This is GPU iteration number 95\n",
      "This is GPU iteration number 96\n",
      "This is GPU iteration number 97\n",
      "This is GPU iteration number 98\n",
      "This is GPU iteration number 99\n",
      "This is GPU iteration number 60\n",
      "This is GPU iteration number 61\n",
      "This is GPU iteration number 62\n",
      "This is GPU iteration number 63\n",
      "This is GPU iteration number 64\n",
      "This is GPU iteration number 65\n",
      "This is GPU iteration number 66\n",
      "This is GPU iteration number 67\n",
      "This is GPU iteration number 68\n",
      "This is GPU iteration number 69\n",
      "This is GPU iteration number 70\n",
      "This is GPU iteration number 71\n",
      "This is GPU iteration number 72\n",
      "This is GPU iteration number 73\n",
      "This is GPU iteration number 74\n",
      "This is GPU iteration number 75\n",
      "This is GPU iteration number 76\n",
      "This is GPU iteration number 77\n",
      "This is GPU iteration number 78\n",
      "This is GPU iteration number 79\n",
      "This is GPU iteration number 180\n",
      "This is GPU iteration number 181\n",
      "This is GPU iteration number 182\n",
      "This is GPU iteration number 183\n",
      "This is GPU iteration number 184\n",
      "This is GPU iteration number 185\n",
      "This is GPU iteration number 186\n",
      "This is GPU iteration number 187\n",
      "This is GPU iteration number 188\n",
      "This is GPU iteration number 189\n",
      "This is GPU iteration number 190\n",
      "This is GPU iteration number 191\n",
      "This is GPU iteration number 192\n",
      "This is GPU iteration number 193\n",
      "This is GPU iteration number 194\n",
      "This is GPU iteration number 195\n",
      "This is GPU iteration number 196\n",
      "This is GPU iteration number 197\n",
      "This is GPU iteration number 198\n",
      "This is GPU iteration number 199\n",
      "This is GPU iteration number 100\n",
      "This is GPU iteration number 101\n",
      "This is GPU iteration number 102\n",
      "This is GPU iteration number 103\n",
      "This is GPU iteration number 104\n",
      "This is GPU iteration number 105\n",
      "This is GPU iteration number 106\n",
      "This is GPU iteration number 107\n",
      "This is GPU iteration number 108\n",
      "This is GPU iteration number 109\n",
      "This is GPU iteration number 110\n",
      "This is GPU iteration number 111\n",
      "This is GPU iteration number 112\n",
      "This is GPU iteration number 113\n",
      "This is GPU iteration number 114\n",
      "This is GPU iteration number 115\n",
      "This is GPU iteration number 116\n",
      "This is GPU iteration number 117\n",
      "This is GPU iteration number 118\n",
      "This is GPU iteration number 119\n",
      "This is GPU iteration number 40\n",
      "This is GPU iteration number 41\n",
      "This is GPU iteration number 42\n",
      "This is GPU iteration number 43\n",
      "This is GPU iteration number 44\n",
      "This is GPU iteration number 45\n",
      "This is GPU iteration number 46\n",
      "This is GPU iteration number 47\n",
      "This is GPU iteration number 48\n",
      "This is GPU iteration number 49\n",
      "This is GPU iteration number 50\n",
      "This is GPU iteration number 51\n",
      "This is GPU iteration number 52\n",
      "This is GPU iteration number 53\n",
      "This is GPU iteration number 54\n",
      "This is GPU iteration number 55\n",
      "This is GPU iteration number 56\n",
      "This is GPU iteration number 57\n",
      "This is GPU iteration number 58\n",
      "This is GPU iteration number 59\n",
      "This is GPU iteration number 160\n",
      "This is GPU iteration number 161\n",
      "This is GPU iteration number 162\n",
      "This is GPU iteration number 163\n",
      "This is GPU iteration number 164\n",
      "This is GPU iteration number 165\n",
      "This is GPU iteration number 166\n",
      "This is GPU iteration number 167\n",
      "This is GPU iteration number 168\n",
      "This is GPU iteration number 169\n",
      "This is GPU iteration number 170\n",
      "This is GPU iteration number 171\n",
      "This is GPU iteration number 172\n",
      "This is GPU iteration number 173\n",
      "This is GPU iteration number 174\n",
      "This is GPU iteration number 175\n",
      "This is GPU iteration number 176\n",
      "This is GPU iteration number 177\n",
      "This is GPU iteration number 178\n",
      "This is GPU iteration number 179\n",
      "This is GPU iteration number 20\n",
      "This is GPU iteration number 21\n",
      "This is GPU iteration number 22\n",
      "This is GPU iteration number 23\n",
      "This is GPU iteration number 24\n",
      "This is GPU iteration number 25\n",
      "This is GPU iteration number 26\n",
      "This is GPU iteration number 27\n",
      "This is GPU iteration number 28\n",
      "This is GPU iteration number 29\n",
      "This is GPU iteration number 30\n",
      "This is GPU iteration number 31\n",
      "This is GPU iteration number 32\n",
      "This is GPU iteration number 33\n",
      "This is GPU iteration number 34\n",
      "This is GPU iteration number 35\n",
      "This is GPU iteration number 36\n",
      "This is GPU iteration number 37\n",
      "This is GPU iteration number 38\n",
      "This is GPU iteration number 39\n",
      "This is GPU iteration number 140\n",
      "This is GPU iteration number 141\n",
      "This is GPU iteration number 142\n",
      "This is GPU iteration number 143\n",
      "This is GPU iteration number 144\n",
      "This is GPU iteration number 145\n",
      "This is GPU iteration number 146\n",
      "This is GPU iteration number 147\n",
      "This is GPU iteration number 148\n",
      "This is GPU iteration number 149\n",
      "This is GPU iteration number 150\n",
      "This is GPU iteration number 151\n",
      "This is GPU iteration number 152\n",
      "This is GPU iteration number 153\n",
      "This is GPU iteration number 154\n",
      "This is GPU iteration number 155\n",
      "This is GPU iteration number 156\n",
      "This is GPU iteration number 157\n",
      "This is GPU iteration number 158\n",
      "This is GPU iteration number 159\n",
      "This is GPU iteration number 0\n",
      "This is GPU iteration number 1\n",
      "This is GPU iteration number 2\n",
      "This is GPU iteration number 3\n",
      "This is GPU iteration number 4\n",
      "This is GPU iteration number 5\n",
      "This is GPU iteration number 6\n",
      "This is GPU iteration number 7\n",
      "This is GPU iteration number 8\n",
      "This is GPU iteration number 9\n",
      "This is GPU iteration number 10\n",
      "This is GPU iteration number 11\n",
      "This is GPU iteration number 12\n",
      "This is GPU iteration number 13\n",
      "This is GPU iteration number 14\n",
      "This is GPU iteration number 15\n",
      "This is GPU iteration number 16\n",
      "This is GPU iteration number 17\n",
      "This is GPU iteration number 18\n",
      "This is GPU iteration number 19\n",
      "This is GPU iteration number 120\n",
      "This is GPU iteration number 121\n",
      "This is GPU iteration number 122\n",
      "This is GPU iteration number 123\n",
      "This is GPU iteration number 124\n",
      "This is GPU iteration number 125\n",
      "This is GPU iteration number 126\n",
      "This is GPU iteration number 127\n",
      "This is GPU iteration number 128\n",
      "This is GPU iteration number 129\n",
      "This is GPU iteration number 130\n",
      "This is GPU iteration number 131\n",
      "This is GPU iteration number 132\n",
      "This is GPU iteration number 133\n",
      "This is GPU iteration number 134\n",
      "This is GPU iteration number 135\n",
      "This is GPU iteration number 136\n",
      "This is GPU iteration number 137\n",
      "This is GPU iteration number 138\n",
      "This is GPU iteration number 139\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 -o multi-block-loop 04-loops/02-multi-block-loop.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## GPU 및 CPU에서 액세스할 메모리 할당\n",
    "\n",
    "최근 버전의 CUDA(버전 6 이상)에서는 CPU 호스트와 여러 개의 GPU 디바이스에서 사용할 수 있는 메모리를 쉽게 할당할 수 있습니다. 가속 애플리케이션에서 최적의 성능을 지원하는 메모리 관리를 위한 [중급 및 고급 기술](http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#memory-optimizations)이 많이 나와 있지만, 이제 우리가 다루게 될 가장 기본적인 CUDA 메모리 관리 기술은 개발자 오버헤드가 거의 없으며 CPU 전용 애플리케이션 대비 환상적인 성능 향상을 지원합니다.\n",
    "\n",
    "메모리를 할당 및 해제하고, 호스트 및 디바이스 코드 모두에서 참조할 수 있는 포인터를 얻으려면 다음 예시와 같이 `malloc` 및 `free`로의 호출을 `cudaMallocManaged` 및 `cudaFree`로 교체하세요.\n",
    "\n",
    "```cpp\n",
    "// CPU-only\n",
    "\n",
    "int N = 2<<20;\n",
    "size_t size = N * sizeof(int);\n",
    "\n",
    "int *a;\n",
    "a = (int *)malloc(size);\n",
    "\n",
    "// Use `a` in CPU-only program.\n",
    "\n",
    "free(a);\n",
    "```\n",
    "\n",
    "```cpp\n",
    "// Accelerated\n",
    "\n",
    "int N = 2<<20;\n",
    "size_t size = N * sizeof(int);\n",
    "\n",
    "int *a;\n",
    "// Note the address of `a` is passed as first argument.\n",
    "cudaMallocManaged(&a, size);\n",
    "\n",
    "// Use `a` on the CPU and/or on any GPU in the accelerated system.\n",
    "\n",
    "cudaFree(a);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 호스트와 디바이스 모두에서 어레이 조작\n",
    "\n",
    "[`01-double-elements.cu`](../edit/05-allocate/01-double-elements.cu) 프로그램은 어레이를 할당하여 호스트의 정수 값으로 초기화하고, GPU에서 병렬로 각 값을 더블링한 다음, 호스트에서 더블링 연산 성공 여부를 확인합니다. 현재는 프로그램이 작동하지 않습니다. 호스트와 디바이스 모두에서 포인터 `a`의 어레이로 상호 작용을 시도하고 있지만, (`malloc`을 사용하여) 호스트에서만 액세스할 수 있도록 어레이가 할당되었습니다. 다음 조건을 만족하도록 애플리케이션을 리팩터링하세요. 도중에 막히면 [해답](../edit/05-allocate/solutions/01-double-elements-solution.cu)을 참고하세요.\n",
    "\n",
    "- `a`는 호스트 및 디바이스 코드 모두에서 사용할 수 있어야 합니다.\n",
    "- `a`의 메모리가 올바르게 해제되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All elements were doubled? TRUE\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 -o double-elements 05-allocate/01-double-elements.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid 크기와 작업량 불일치\n",
    "\n",
    "다음 슬라이드에서는 앞으로 다룰 콘텐츠를 고수준에서 시각적으로 보여드립니다. 다음 섹션으로 넘어가 각 주제를 더 자세히 다루기 전에 슬라이드를 클릭해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vQZjfKvoLhR4lVWB73QxecFlpzvwJ9EHbwk_cjXXhE3vKALU_uuClEzeBmEcFPmGS6J3aZud70EiLGH/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vQZjfKvoLhR4lVWB73QxecFlpzvwJ9EHbwk_cjXXhE3vKALU_uuClEzeBmEcFPmGS6J3aZud70EiLGH/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 필요한 스레드 수와 블록 구성 간의 불일치 처리\n",
    "\n",
    "루프 병렬화에 필요한 정확한 스레드 수를 생성하는 실행 구성을 표현할 수 없는 경우가 있습니다.\n",
    "\n",
    "일반적인 예 중 하나는 최적의 블록 크기를 선택하고자 하는 욕구와 관계가 있습니다. 예를 들어, GPU 하드웨어의 특성으로 인해 블록에 포함된 스레드 수가 32의 배수인 경우 성능적 이점을 누릴 수 있습니다. 각각 256개(32의 배수)의 스레드를 포함하는 블록을 실행하고 싶다고 가정할 때, 1000개의 병렬 작업을 실행해야 한다면(설명 편의상 작은 수로), 32를 곱했을 때 정확히 1000이 되는 정수는 없으므로 그리드 내에 정확히 총 1000개의 스레드를 생성하는 블록의 수는 존재하지 않습니다.\n",
    "\n",
    "이 시나리오는 다음 방법으로 쉽게 해결할 수 있습니다.\n",
    "\n",
    "- 할당된 작업을 수행하기 위해 필요한 것보다 **많은** 스레드를 생성하는 실행 구성을 작성합니다.\n",
    "- 처리될 데이터세트의 총 크기 또는 작업을 완료하는 데 필요한 총 스레드를 나타내는 값을 커널에 인수로 전달합니다(`N`).\n",
    "- 그리드 내의 스레드 색인을 계산한 후(`tid+bid*bdim` 사용) 색인이 `N`을 초과하지 않는지 확인하고, 초과하지 않는 경우에만 커널의 관련 작업을 수행합니다.\n",
    "\n",
    "다음은 `N`과 블록의 스레드 수를 둘 다 알고, 그리드의 스레드 수와 `N`의 정확한 일치를 보장할 수 없는 경우에 실행 구성을 작성하는 관용적인 방법의 예입니다. 최소한 `N`에 필요한 만큼의 스레드가 항상 있고 추가할 수 있는 스레드 블록은 최대 1개이도록 합니다.\n",
    "\n",
    "```cpp\n",
    "// Assume `N` is known\n",
    "int N = 100000;\n",
    "\n",
    "// Assume we have a desire to set `threads_per_block` exactly to `256`\n",
    "size_t threads_per_block = 256;\n",
    "\n",
    "// Ensure there are at least `N` threads in the grid, but only 1 block's worth extra\n",
    "size_t number_of_blocks = (N + threads_per_block - 1) / threads_per_block;\n",
    "\n",
    "some_kernel<<<number_of_blocks, threads_per_block>>>(N);\n",
    "```\n",
    "\n",
    "위의 실행 구성은 그리드 내에 `N`보다 더 많은 스레드를 야기하기 때문에, `some_kernel`이 \"extra\" 스레드 중 하나에 의해 실행될 때 범위 외의 데이터 요소에 액세스하려고 시도하지 않도록 `some_kernel` 정의 내에서 더 많은 신경을 써야 합니다.\n",
    "\n",
    "```cpp\n",
    "__global__ some_kernel(int N)\n",
    "{\n",
    "  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "\n",
    "  if (idx < N) // Check to make sure `idx` maps to some value within `N`\n",
    "  {\n",
    "    // Only do work if it does\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 실행 구성이 불일치하는 For 루프 가속\n",
    "\n",
    "[`02-mismatched-config-loop.cu`](../edit/05-allocate/02-mismatched-config-loop.cu)에 있는 프로그램은 `cudaMallocManaged`를 사용하여 정수 1000개 요소 어레이에 메모리를 할당하고, CUDA 커널을 사용하여 병렬로 어레이의 모든 값을 초기화하려고 합니다. 이 프로그램은 `N`과 `threads_per_block`의 수가 모두 알려져 있다고 가정합니다. 여러분이 할 일은 다음 두 목표를 완료하는 것이고, 도중에 막히면 [해답](../edit/05-allocate/solutions/02-mismatched-config-loop-solution.cu)을 참고하세요.\n",
    "\n",
    "- 최소한 `a`에서 작업해야 할 요소 수만큼의 스레드가 있도록 하는 `number_of_blocks` 값을 할당하세요.\n",
    "- 범위 밖의 데이터 요소에 대한 작업을 시도하지 않도록 `initializeElementsTo` 커널을 업데이트하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 -o mismatched-config-loop 05-allocate/02-mismatched-config-loop.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 그리드 스트라이드 루프\n",
    "\n",
    "다음 슬라이드에서는 앞으로 다룰 콘텐츠를 고수준에서 시각적으로 보여드립니다. 다음 섹션으로 넘어가 각 주제를 더 자세히 다루기 전에 슬라이드를 클릭해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div align=\"center\"><iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTSfcPagyv7ObRnhygFnKrvDIDa-wUuc3yR-qs7xd4gQxProMOqXzNqe8y9vz711cLIbPp1qYJc7R3l/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<div align=\"center\"><iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTSfcPagyv7ObRnhygFnKrvDIDa-wUuc3yR-qs7xd4gQxProMOqXzNqe8y9vz711cLIbPp1qYJc7R3l/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 그리드보다 큰 데이터세트\n",
    "\n",
    "가장 수행성 높은 실행 구성을 생성하기 위해 선택한 것이든 필요에 의한 것이든, 그리드의 스레드 수가 데이터세트의 크기보다 작을 수도 있습니다. 어레이에는 1000개의 요소가 있고 그리드에는 250개의 스레드가 있다고 생각해 보세요(설명 편의상 작은 크기를 사용합니다). 이 경우, 그리드의 각 스레드를 4번 사용해야 합니다. 이 작업을 하는 한 가지 일반적인 방법은 커널 내에서 **그리드 스트라이드 루프**를 사용하는 것입니다.\n",
    "\n",
    "그리드 스트라이드 루프에서는 각 스레드가 `tid+bid*bdim`을 사용하여 그리드 내의 고유한 색인을 계산하고, 어레이 내의 해당 색인에서 요소의 연산을 수행한 다음, 그리드의 스레드 수를 색인에 추가하고, 어레이 범위를 벗어날 때까지 이를 반복합니다. 예를 들어, 500개의 요소가 있는 어레이와 250개의 스레드가 있는 그리드의 경우, 그리드에서 색인 20을 가진 스레드는 다음을 진행합니다.\n",
    "\n",
    "- 요소 500개짜리 어레이의 요소 20에서 연산 수행\n",
    "- 색인을 그리드의 크기인 250으로 증분하여 270 도출\n",
    "- 요소 500개짜리 어레이의 요소 270에서 연산 수행\n",
    "- 색인을 그리드의 크기인 250으로 증분하여 520 도출\n",
    "- 520은 어레이 범위에서 벗어났으므로 스레드 작업 중지\n",
    "\n",
    "CUDA는 그리드의 블록 수를 지정하는 특수 변수 `gridDim.x`를 제공합니다. 그렇다면 그리드의 총 스레드 수는 단순히 그리드의 블록 수에 각 블록의 스레드 수를 곱해 `gridDim.x * blockDim.x`로 계산할 수 있습니다. 이를 염두에 두고, 커널 내 그리드 스트라이드 루프에 대한 다음의 세세한 예시를 살펴봅시다.\n",
    "\n",
    "```cpp\n",
    "__global__ void kernel(int *a, int N)\n",
    "{\n",
    "  int indexWithinTheGrid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  int gridStride = gridDim.x * blockDim.x;\n",
    "\n",
    "  for (int i = indexWithinTheGrid; i < N; i += gridStride)\n",
    "  {\n",
    "    // do work on a[i];\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 그리드 스트라이드 루프를 사용하여 그리드보다 큰 어레이 조작\n",
    "\n",
    "`N`보다 작은 그리드가 스레드를 재사용하여 어레이의 모든 요소를 커버할 수 있게 하기 위해 `doubleElements` 커널에서 그리드 스트라이드 루프를 사용하도록 [`03-grid-stride-double.cu`](../edit/05-allocate/03-grid-stride-double.cu)를 리팩터링하세요. 이 프로그램은 어레이의 모든 요소가 더블링되었는지를 출력합니다. 현재는 프로그램이 정확히 `FALSE`를 출력합니다. 도중에 막히면 [해답](../edit/05-allocate/solutions/03-grid-stride-double-solution.cu)을 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All elements were doubled? TRUE\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 -o grid-stride-double 05-allocate/03-grid-stride-double.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 오류 처리\n",
    "\n",
    "모든 애플리케이션에서와 같이, 가속 CUDA 코드에서도 오류 처리는 필수적입니다. 대부분의 CUDA 함수(예: [메모리 관리 함수](http://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY) 참조)는 `cudaError_t` 형식 값을 반환하며, 이를 사용하여 함수 호출 중 오류가 발생했는지를 확인할 수 있습니다. 다음은 `cudaMallocManaged`로의 호출에 대해 오류 처리가 수행되는 예시입니다.\n",
    "\n",
    "```cpp\n",
    "cudaError_t err;\n",
    "err = cudaMallocManaged(&a, N)                    // Assume the existence of `a` and `N`.\n",
    "\n",
    "if (err != cudaSuccess)                           // `cudaSuccess` is provided by CUDA.\n",
    "{\n",
    "  printf(\"Error: %s\\n\", cudaGetErrorString(err)); // `cudaGetErrorString` is provided by CUDA.\n",
    "}\n",
    "```\n",
    "\n",
    "`void`를 반환하도록 정의된 커널을 실행하면 `cudaError_t` 형식의 값을 반환하지 않습니다. 커널 실행 시 발생하는 오류(예: 시작 구성에 오류가 있는지 여부)를 확인하기 위해 CUDA는 `cudaError_t` 형식 값을 반환하는 `cudaGetLastError` 함수를 제공합니다.\n",
    "\n",
    "```cpp\n",
    "/*\n",
    " * This launch should cause an error, but the kernel itself\n",
    " * cannot return it.\n",
    " */\n",
    "\n",
    "someKernel<<<1, -1>>>();  // -1 is not a valid number of threads.\n",
    "\n",
    "cudaError_t err;\n",
    "err = cudaGetLastError(); // `cudaGetLastError` will return the error from above.\n",
    "if (err != cudaSuccess)\n",
    "{\n",
    "  printf(\"Error: %s\\n\", cudaGetErrorString(err));\n",
    "}\n",
    "```\n",
    "\n",
    "마지막으로, 비동기적으로 발생하는 오류를 잡아내기 위해(예: 비동기 커널 실행 중) 후속 동기화 cuda 런타임 API 호출로 반환된 상태를 확인하는 것이 중요합니다. 예를 들어 `cudaDeviceSynchronize`는 이전에 실행된 커널 중 하나가 실패할 경우 오류를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 오류 처리 추가\n",
    "\n",
    "현재 [`01-add-error-handling.cu`](../edit/06-errors/01-add-error-handling.cu)는 컴파일 및 실행을 거쳐 어레이의 요소가 성공적으로 더블링되지 않았음을 출력합니다. 그러나 프로그램에 오류가 있다고 표시되지는 않습니다. 프로그램에서 CUDA 오류를 처리하여 무엇이 잘못되었는지 알아보고 효과적으로 디버그할 수 있도록 애플리케이션을 리팩터링하세요. CUDA 함수를 호출할 때 잠재적으로 생성되는 동기 오류와 CUDA 커널이 실행되는 동안 잠재적으로 생성될 수 있는 비동기 오류 모두를 조사해야 합니다. 도중에 막히면 [해답](../edit/06-errors/solutions/01-add-error-handling-solution.cu)을 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: invalid configuration argument\r\n",
      "All elements were doubled? FALSE\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 -o add-error-handling 06-errors/01-add-error-handling.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### CUDA 오류 처리 함수\n",
    "\n",
    "오류 확인을 위해 CUDA 함수 호출을 래핑하는 매크로를 만드는 것이 유용할 수 있습니다. 다음의 예시를 남아 있는 연습문제에서 자유롭게 사용하시기 바랍니다.\n",
    "\n",
    "```cpp\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "\n",
    "inline cudaError_t checkCuda(cudaError_t result)\n",
    "{\n",
    "  if (result != cudaSuccess) {\n",
    "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
    "    assert(result == cudaSuccess);\n",
    "  }\n",
    "  return result;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "\n",
    "/*\n",
    " * The macro can be wrapped around any function returning\n",
    " * a value of type `cudaError_t`.\n",
    " */\n",
    "\n",
    "  checkCuda( cudaDeviceSynchronize() )\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 요약\n",
    "\n",
    "여러분은 이 시점에서 다음의 실습 목표를 모두 달성하셨습니다.\n",
    "\n",
    "- CPU 함수를 호출하고 **GPU** 커널을 **실행하는** C/C++ 프로그램 작성, 컴파일, 실행\n",
    "- **실행 구성**을 이용한 병렬 **스레드 계층 구조** 제어\n",
    "- 직렬 루프를 GPU에서 병렬로 반복 실행하도록 리팩터링\n",
    "- CPU와 GPU 둘 다에서 사용할 수 있는 메모리 할당 및 해제\n",
    "- CUDA 코드로 생성된 오류 처리\n",
    "\n",
    "이제 실습의 최종 목표인\n",
    "\n",
    "- CPU 전용 애플리케이션 가속화를 완료하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 최종 연습문제: 벡터 추가 애플리케이션 가속\n",
    "\n",
    "다음 도전 과제는 여러분이 지금까지 실습에서 배운 모든 것을 사용하실 수 있는 기회입니다. 이 문제에서 다룰 CPU 전용 벡터 추가 프로그램은 아주 정교한 프로그램은 아니지만, CUDA를 이용한 GPU 가속 애플리케이션에 대해 여러분이 배운 것에 집중할 수 있는 기회가 될 것입니다. 이 연습문제를 완료하고 나서 시간과 관심이 있으신 경우 계속해서 *고급 콘텐츠* 섹션에서 더 복잡한 코드베이스를 다루는 몇 가지 과제에 도전해 보세요.\n",
    "\n",
    "[`01-vector-add.cu`](../edit/07-vector-add/01-vector-add.cu)에는 작동하고 있는 CPU 전용 벡터 추가 애플리케이션이 포함되어 있습니다. `addVectorsInto` 함수가 GPU에서 CUDA 커널로 실행되어 병렬로 작업을 수행할 수 있도록 가속화하세요. 다음의 사항이 만족되어야 한다는 것을 생각하며 해 보시고, 도중에 막히면 [해답](../edit/07-vector-add/solutions/01-vector-add-solution.cu)을 을 참고하세요.\n",
    "\n",
    "- `addVectorsInto` 정의를 CUDA 커널이 되도록 증강하세요.\n",
    "- `addVectorsInto`가 CUDA 커널로 실행될 수 있도록 작동 중인 실행 구성을 선택 및 활용하세요.\n",
    "- 호스트 및 디바이스 코드가 3개의 벡터 `a`, `b`, `result`에 액세스해야 한다는 점을 반영하도록 메모리 할당과 메모리 해제를 업데이트하세요.\n",
    "- `addVectorsInto`의 바디를 리팩터링하세요. 하나의 스레드 내에서 실행되며 입력 벡터에서 1개 스레드 분량의 작업만 실행할 수 있으면 됩니다. 스레드가 입력 벡터 범위 밖에 있는 요소에 액세스하려고 시도하지 않도록 하시고, 스레드가 입력 벡터의 요소 한 개 이상에서 작업해야 하는지 여부에 유의하세요.\n",
    "- CUDA 코드가 눈에 띄지 않게 실패할지도 모르는 위치에 오류 처리를 추가하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_70 -o vector-add 07-vector-add/01-vector-add.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 고급 콘텐츠\n",
    "\n",
    "다음 연습문제는 시간과 관심이 있는 분들에게 추가적인 도전 과제를 드리기 위한 것입니다. 보다 고난이도의 테크닉을 사용해야 하며, 더 적은 스캐폴딩을 제공합니다. 어려운 만큼 실력 향상에 큰 도움이 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2차원 및 3차원의 그리드와 블록\n",
    "\n",
    "그리드와 블록은 최대 3차원으로 정의할 수 있습니다. 다중 차원 정의는 어떤 식으로든 성능에는 영향을 끼치지 않지만, 예를 들어 2D 행렬처럼 다중 차원을 가진 데이터를 처리할 때 매우 유용하게 쓸 수 있습니다. 2차원 또는 3차원으로 그리드 또는 블록을 정의하기 위해서는 다음과 같은 CUDA의 `dim3` 유형을 사용합니다.\n",
    "\n",
    "```cpp\n",
    "dim3 threads_per_block(16, 16, 1);\n",
    "dim3 number_of_blocks(16, 16, 1);\n",
    "someKernel<<<number_of_blocks, threads_per_block>>>();\n",
    "```\n",
    "\n",
    "위에 주어진 예시를 보면 `someKernel` 안의 변수 `gridDim.x`, `gridDim.y`, `blockDim.x`, `blockDim.y`는 모두 `16`이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 2D 행렬 곱셈 애플리케이션 가속\n",
    "\n",
    "파일 [`01-matrix-multiply-2d.cu`](../edit/08-matrix-multiply/01-matrix-multiply-2d.cu)에는 완전하게 작동하는 호스트 함수 `matrixMulCPU`가 포함되어 있습니다. 여러분이 할 일은 `matrixMulGPU` CUDA 커널을 만들어내는 것입니다. 소스 코드가 두 함수 모두에서 행렬 곱셈을 실행하고 답을 비교하여 여러분이 작성할 CUDA 커널이 올바른지 확인합니다. 다음 가이드라인을 활용하여 작업하시고, 도중에 막히면 [해답](../edit/08-matrix-multiply/solutions/01-matrix-multiply-2d-solution.cu)을 참고하세요.\n",
    "\n",
    "- `x` 및 `y` 차원이 `1`보다 크게 설정된 두 `dim3` 값 모두가 인수인 실행 구성을 생성해야 합니다.\n",
    "- 커널 바디 내에는 평소처럼 그리드 내에서 실행되는 스레드의 고유한 색인을 설정해야 하지만, 이번에는 스레드에 두 개의 색인(그리드의 x축에 하나, 그리드의 y 축에 하나)을 설정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_70 -o matrix-multiply-2d 08-matrix-multiply/01-matrix-multiply-2d.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 연습문제: 열전도 애플리케이션 가속\n",
    "\n",
    "다음 연습문제에서는 2차원 공간에서 은의 열전도를 시뮬레이션하는 애플리케이션을 가속화하게 됩니다.\n",
    "\n",
    "[`01-heat-conduction.cu`](../edit/09-heat/01-heat-conduction.cu) 내의 `step_kernel_mod` 함수를 GPU에서 실행되도록 변환하고, CPU 및 GPU에서 사용할 데이터를 적절하게 할당하도록 `main` 함수를 수정하세요. `step_kernel_ref` 함수는 CPU에서 실행되며 오류 검사에 사용됩니다. 이 코드는 부동 소수점 계산, 다양한 프로세서, 또는 간단히 같은 프로세서에서 연산을 재구성하는 작업을 포함하기 때문에 결과가 약간 다를 수 있습니다. 이러한 이유로 오류 검사 코드는 정확한 일치를 찾는 대신 오류 임계값을 사용합니다. 도중에 막히면 [해답](../edit/09-heat/solutions/01-heat-conduction-solution.cu)을 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_70 -o heat-conduction 09-heat/01-heat-conduction.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 열전도 CPU 소스 코드의 원래 출처는 휴스턴대학교의 [C 기반 열전도 코드용 OpenACC 예시 코드](http://docplayer.net/30411068-An-openacc-example-code-for-a-c-based-heat-conduction-code.html) 문서입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
